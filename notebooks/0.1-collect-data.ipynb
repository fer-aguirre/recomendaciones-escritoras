{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.exceptions import MissingSchema\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "import recomendaciones_escritoras.data.load as load"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodreads_escritoras = load.goodreads_escritoras\n",
    "data_processed = load.data_processed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file as dataframe\n",
    "df = pd.read_csv(goodreads_escritoras, converters={'id': str})\n",
    "\n",
    "# Convert columns to lists\n",
    "nombres = df['nombre'].to_list()\n",
    "urls = df['url'].to_list()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 133/1116 [09:36<1:20:53,  4.94s/it]"
     ]
    }
   ],
   "source": [
    "# Create an empty list\n",
    "dfs = []\n",
    "# Iterate trhough\n",
    "for i in tqdm(range(len(urls))):\n",
    "\n",
    "    try:\n",
    "        # Make http request\n",
    "        response = requests.get(urls[i])\n",
    "\n",
    "        # Return content of the response\n",
    "        html = response.text\n",
    "        # Parse html\n",
    "        soup = bs(html, 'html.parser')\n",
    "\n",
    "        # Look for <a> tags inside <tr> tag\n",
    "        results = [tr.find('a', attrs={'class':'bookTitle'}) for tr in soup.find_all('tr')]\n",
    "\n",
    "        # Extract 'href' from <a> tag and build a link\n",
    "        book_url = ['https://www.goodreads.com' + i.get(\"href\") for i in results]\n",
    "\n",
    "        # Create dataframe from list\n",
    "        df = pd.DataFrame(book_url, columns=['book_url'])\n",
    "\n",
    "        # Create new column\n",
    "        df['nombre'] = nombres[i]\n",
    "\n",
    "        # Append dataframes to list\n",
    "        dfs.append(df)\n",
    "\n",
    "        # Sleep a random number of seconds (between 1 and 5)\n",
    "        sleep(randint(1,5))\n",
    "    \n",
    "    except MissingSchema:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join lists on dataframes\n",
    "df_books = pd.concat(dfs)\n",
    "\n",
    "# Show dataframe\n",
    "df_books"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe as csv file\n",
    "df_books.to_csv(f'{data_processed}/goodreads_libros.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recomendaciones_escritoras-VtlOqYSf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
